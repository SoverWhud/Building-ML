{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тематическое (Topic) моделирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно группировать текстовые документы с применением __методов кластеризации__. Это средство весьма полезное, но не всегда наилучшее. Оно приводит к тому, что каждый текст попадает в один и только один кластер. Но, допустим есть книга посвященная машинному обучению и языку Python. Куда ее отнести - к работам по теме \"Python\", или по теме \"машинное обучение\". В реальном книжном магазине книгу нужно поместить на какую-то одну полку. Но в Интернет-магазине она должна присутствовать в обеих рубриках. Но это не значит, что ее следует включать во все вообще рубрики, скажем, в раздел, посвященный кулинарии.\n",
    "\n",
    "В этой главе мы познакомимся с методами, которые позволяют относить каждый документ к нескольким __темам (topics)__, а не помещать в одинединственный кластер. __Темы будут определяться автоматически__ по имеющемуся набору документов. __Документами могут быть__ как книги, так и более короткие тексты, например, сообщенне в блоге, новость или электронное письмо.\n",
    "\n",
    "Хотелось бы уметь __определять центральную (central) и второстепенные (referring to other topics) темы документа__. \n",
    "\n",
    "Отрасль машинного обучения, в которой рассматриваются подобные проблемы и которой посвящена эта глава, называется __тематическим моделированием (topic modeling)__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Латентное размещение Дирихле (latent Dirichlet allocation LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так получилось, что в машинном обучении есть два метода с аббревиатурой __LDA__: \n",
    "1. __Латентное размещение Дирихле (latent Dirichlet allocation)__, один из алгоритмов тематического моделирования, \n",
    "2. __Линейный дискриминантный анализ (linear discriminant analysis)__ - алгоритм классификации. \n",
    "\n",
    "Кроме аббревиатуры, у них нет ничего общего, и иногда это приводит к недоразумениям. В модуле scikit-learn\n",
    "есть подмодуль __sklearn.lda__, в котором реализован линейный дискриминантный анализ. В настоящее время __метод латентного размещеиия Дирихле в scikit-learn не реализован__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Математические идеи, лежащие в основе метода латентного размещения Дирихле, довольно сложны. Однако можно составить общее представление о LDA на интуитивном уровне. LDA принадлежит к классу так называемых __порождающих моделей (generative models)__, поскольку они сопровождаются пояснением, описывающим, как были сгенерированы данные. Разумеется, это пояснение - всего лишь приближение к реальности, призванное упростить машинное обучение. \n",
    "\n",
    "В LDA мы сначала создаем темы, назначая словам __веса в форме вероятностей (probability weights)__. В каждой теме одному и тому же слову назначены разные веса. Так, в теме \"Python\" у слова \"variable\" (переменная) будет высокая вероятность, а у слова \"inebriated\" (подвыпивший) - низкая. Желая сгенерировать новый документ, мы сначала\n",
    "выбираем соответствующие ему темы, а затем комбинируем слова, относящиеся к этим темам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть, например, в книгах обсуждаются всего три темы:\n",
    "* машинное обучение;\n",
    "* язык Python;\n",
    "* кулинария.\n",
    "\n",
    "__С каждой темой ассоциирован список слов__. В одной книге будут встречаться слова из первых двух тем, положим, в пропорции 50/50. Доли необязательно должны быть одинаковыми, возможно и соотношение 70/30. Порождая новый текст, мы\n",
    "выбираем слово за словом. Сначала решаем, из какой темы брать слово; решение принимается случайно, но в соответствии с весами тем. Определившись с темой, мы выбираем слово нз списка английских слов, ассоциированных с этой темой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой модели порядок слов не играет роли. То есть это __модель набора слов (bag of words)__. Это очень грубое приближение к реалыюму языку, но часто оно оказывается достаточным, потому что одно лишь знание частот слов, встречающихся в документе, позволяет принимать, решения в алгоритмах машинного обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На практике темы нам заранее неизвестны. Наша задача - __получить набор текстов и восстановить по нему пояснение (reverse engineer this fable)__, то есть выяснить, какие темы вообще представлены и к каким из них относится каждый документ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение тематической модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К сожалению, scikit-learn не поддерживает метод латентного размещения Дирихле. Поэтому мы воспользуемся написанным на Python пакетом __gensim__. Этот пакет разработан __Радимом Ржехоржеком__ - исследователем в области машинного обучения и консультантом из Великобритании."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in e:\\python\\anaconda2\\lib\\site-packages\n",
      "Requirement already satisfied: six>=1.5.0 in e:\\python\\anaconda2\\lib\\site-packages (from gensim)\n",
      "Requirement already satisfied: scipy>=0.7.0 in e:\\python\\anaconda2\\lib\\site-packages (from gensim)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in e:\\python\\anaconda2\\lib\\site-packages (from gensim)\n",
      "Requirement already satisfied: numpy>=1.3 in e:\\python\\anaconda2\\lib\\site-packages (from gensim)\n",
      "Requirement already satisfied: requests in e:\\python\\anaconda2\\lib\\site-packages (from smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: boto>=2.32 in e:\\python\\anaconda2\\lib\\site-packages (from smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: bz2file in e:\\python\\anaconda2\\lib\\site-packages (from smart-open>=1.2.1->gensim)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "\n",
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве данных мы возьмем собрание новостей агентства __Associated Press (АР)__. Это стандартный набор данных для исследований по машинному обучению, который использовался в некоторых ранних работах по тематическому моделированию. Скачав данные, загрузим их в память:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = corpora.BleiCorpus('./data/ap/ap.dat', './data/ap/vocab.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "В переменной __corpus__ хранятся все текстовые документы в формате, удобном для обработки. Теперь мы можем построить на основе этого объекта __тематическую модель__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = models.ldamodel.LdaModel(corpus, num_topics=100, id2word=corpus.id2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате этого вызова конструктора будет статистически сделан вывод, какие темы присутствуют в корпусе. Получившуюся молель можно исследовать с разных точек зрения. Можно с помощью конструкции __model[doc]__ вывести список\n",
    "тем, ассоциированных с документом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.042080634668475933),\n",
       " (3, 0.19344071954097458),\n",
       " (14, 0.047543847381963593),\n",
       " (28, 0.10687944778272351),\n",
       " (29, 0.30615464540751264),\n",
       " (43, 0.010506012251037278),\n",
       " (61, 0.078290651097378178),\n",
       " (69, 0.026758224717463971),\n",
       " (74, 0.010275350171067609),\n",
       " (77, 0.041766519320765735),\n",
       " (82, 0.057323252256790871),\n",
       " (99, 0.040403952020450752)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = corpus.docbyoffset(0)\n",
    "topics = model[doc]\n",
    "topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__В обучающем алгоритме используются случайные величины__, поэтому при многократном обучении тематической модели на одних и тех же данных всякий раз получается новый результат. Но если данные ведут себя хорошо, то __некоторые качественные свойства модели будут неизменны__. Например, если использовать темы для сравнения документов, что мы и делаем, то сходство (similarities) будет устойчивым (robust), слабо изменяющимся свойством (change only slightly). C другой стороны, порядок тем будет совершенно различным"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат выдается в виде списка пар __(topic_index, topic_weight)__. Мы видим, что с каждым документом ассоциирована лишь часть всех тем (в примере выше для некоторых тем вес не указан, то есть равен нулю). __Тематическая модель разрежена__, то есть всего тем много, но каждый отдельный документ принадлежит лишь немногим. Строго говоря, это не совсем так, поскольку __в модели LDA y любой темы ненулевая вероятность__, но для некоторых она настолько мала, что можно считать ее равной нулю, не жертвуя качеством аппроксимации.\n",
    "\n",
    "__Вектор или матрица называют разреженными__, если большая часть элементов равна нулю (или настолько мала, что можно без ущерба для точности решения считать их нулевыми). Поэтому релевантны лишь немногие значения.\n",
    "\n",
    "Часто задачу, кажущуюся неподъемно большой, удается решить, потому что данные разрежены. Например, любая веб-страница теоретически может ссылаться на любую друrую, но на практике граф ссылок очень сильно разрежен, потому что имеются ссылки лишь на небольшое число страниц."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно продолжить исследование и построить гистограмму тем, ассоциированных с документом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_topics_used = [len(model[doc]) for doc in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJANKktQkA0qS1CQDSpLUpP8PuI+6WipS1jAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x83deb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.hist(num_topics_used, np.arange(42), edgecolor='k')\n",
    "ax.set_ylabel('Nr of documents')\n",
    "ax.set_xlabel('Nr of topics')\n",
    "ax.grid()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из графика видно, что примерно 150 документов относятся к 7 темам, а с большинством ассоциировано от 10 до 13 тем. Нет\n",
    "ни одного документа, в котором бы шла речь более чем о 20 разных темах.\n",
    "\n",
    "Это в значительной степени связано с выбором параметра __alpha__. Его точный смысл выражается в очень абстрактных терминах, но __чем больше значение alpha__, тем больше тем будет у каждого документа. Параметр alpha должен быть больше нуля, и обычно берется значение меньше 1. __Чем меньше alpha__, тем меньше ожидаемое количество тем документа. По умолчанию в gensim alpha принимается равным __1/num_topics__, но можно задать значение явно, передав конструктору\n",
    "LdaModel одноименный параметр:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = models.ldamodel.LdaModel(corpus, num_topics=100, id2word=corpus.id2word, alpha=1)\n",
    "num_topics_used1 = [len(model1[doc]) for doc in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAH4hJREFUeJzt3XucVXW9//HXR/TAkav+KA7C/M7QkYsgOjATecEasgtl\noXlM8dIBj/04P7x2rEjjlPOz/EUInvJWkRqUlzmUEmipR8kx+ikRyAjKRUDGZCRIw5HBJAc+vz/2\nmnEzl73XXNbe32G/n4/Hfsxe3+9aa79Zw8xn1u27zN0REREJzRH5DiAiItIaFSgREQmSCpSIiARJ\nBUpERIKkAiUiIkFSgRIRkSCpQImISJBUoEREJEgqUCIiEqQj8x2gMwYOHOjFxcUdXn7fvn307t27\n6wIlQBm7hjJ2Xuj5QBm7StIZ16xZ87q7vy/rjO7ebV+lpaXeGU899VSnls8FZewayth5oedzV8au\nknRGYLXH+B2vQ3wiIhIkFSgREQmSCpSIiARJBUpERIKkAiUiIkFSgZJ2q6ioYN68eRnn+fOf/8yH\nPvQhxo0bx4oVK9r9GQsXLuTKK68E4Je//CUbNmzo8PKdmUdE8kcFShKxfPlyxo4dy9q1aznjjDM6\nta6OFCgR6f5UoCSWm266iREjRjBx4kQ2b97c1L5t2zZmzZpFaWkpZ5xxBps2baK6uppZs2axdOlS\nSkpK+Otf/8rMmTMpKytjzJgx3HDDDU3LFxcX8/rrrwOwevVqysvLD/ncZ555hmXLlvHVr36VkpIS\ntm3bdkj/ww8/3LSn9rGPfYxdu3a1yD59+nRuueUWysrKGDFiBI888khT32uvvcbkyZMZPnw4s2bN\nampvK6+I5E63HklCcmPNmjVUVlZSXV1NQ0MD48ePp7S0FIAZM2Zw9dVXc8kll/D73/+eyy+/nN/8\n5jfceOONrF69mttvvx1IFbhjjz2WAwcOcOaZZ7Ju3TpOOumkrJ992mmnMWXKFD7zmc9w3nnnteif\nOHEiK1euxMy46667mDt3LvPnz28x35/+9CdWrVrFtm3bmDRpElu3bgWgurqatWvX0rNnT0aOHMlV\nV11FUVFRh/OKSNdRgZKsVqxYwav9TmT0jU8BcO6UKQDU19fzzDPP8MorrzSdk9q/f3+r61i8eDEL\nFiygoaGBnTt3smHDhi75hb9jxw4uuOACdu7cyd/+9jeGDRvW6nzl5eUcccQRDB8+nA984ANs2rQJ\ngDPPPJP+/fsDMHr0aF555RWKiooSyysi8ekQn3TYwYMHGTBgAHfddRfV1dVUV1ezcePGFvNt376d\nefPmsXz5ctatW8dZZ53FO++8A8CRRx7JwYMHAZra2uOqq67iyiuvZP369fzoRz9qcx1m1up0z549\nm9p69OhBQ0NDxrwikjsqUJLVhz/8Yd7espKD7+7n4P63efjhhwHo168fw4YNo6qqCkiN6/j888+3\nWP6tt96id+/e9O/fn127dvHoo4829RUXF7NmzRoAHnzwwVY/v2/fvuzdu7fVvrq6OoYMGQLAokWL\n2vw3PP300xw8eJBt27bx8ssvM3LkyDbnzZRXRHJHBUqyGj9+PL1HncHOn1zF7p9X8MEPfrCp7777\n7uPXv/41J598MmPGjGHp0qUtlj/55JMZN24co0aN4qKLLuL0009v6rvhhhu45pprKCsro0ePHq1+\n/tSpU7n55psZN25ci4skKioq+PznP09paSkDBw5s89/w/ve/nwkTJvCpT32KH/7wh/Tq1avNeTPl\nFZEcijOibKgvjWaeO//4tUeaXs2FkrEt06ZN84qKinzHyCr07Rh6Pndl7CoazVxERCQDFSg57C1c\nuJCPfOQj+Y4hIu2kAiUiIkFSgRIRkSCpQImISJBUoEREJEgqUCIiEiQVKBERCZIKlIiIBEkFSkRE\ngqTHbRSA4ut+1fS+Zs5ZeUwiIhKfCpR0CRVBEelqOsQnIiJBUoESEZEgqUCJiEiQVKBERCRIKlAi\nIhKkxAqUmRWZ2VNmtsHMXjSza6L2Y83sCTPbEn09Jm2Z681sq5ltNrNPJpVNRETCl+Rl5g3Al939\nOTPrC6wxsyeA6cByd59jZtcB1wFfM7PRwFRgDHAc8KSZjXD3AwlmPCzoEm8RORwltgfl7jvd/bno\n/V5gIzAEOBtYFM22CDgnen82UOnu+919O7AVmJBUPhERCZu5e/IfYlYM/BY4Efijuw+I2g3Y4+4D\nzOx2YKW73xv13Q086u6/aLauGcAMgEGDBpVWVlZ2OFd9fT19+vTp8PK5ECfj+tq6pvdjh/Rvd38c\nmdZRX1/P9roDbfaH4HD5XudT6PlAGbtK0hknTZq0xt3Lss2X+EgSZtYHeBD4kru/lapJKe7uZtau\nCunuC4AFAGVlZV5eXt7hbFVVVXRm+VyIk3F6+iG+i1vOm60/jkzrqKqqYv7v9nX6M5J0uHyv8yn0\nfKCMXSWUjIlexWdmR5EqTve5+0NR8y4zGxz1DwZ2R+21QFHa4kOjNhERKUBJXsVnwN3ARne/Ja1r\nGTAtej8NWJrWPtXMeprZMGA4sCqpfCIiErYkD/GdDnwBWG9m1VHb14E5wGIzuwx4BTgfwN1fNLPF\nwAZSVwBeoSv4REQKV2IFyt1/B1gb3We2scxNwE1JZZL80aXwItJeGklCRESCpAIlIiJBUoESEZEg\nqUCJiEiQVKBERCRIKlAiIhIkFSgREQmSCpSIiARJBUpERIKkAiUiIkFK/HEb0nkaJkhECpH2oERE\nJEgqUCIiEiQVKBERCZIKlIiIBEkFSkREgqQCJSIiQVKBEhGRIOk+KDnkPivQvVYiEgbtQYmISJBU\noEREJEgqUCIiEiQVKBERCZIKlIiIBEkFSkREgqQCJSIiQVKBEhGRIKlAiYhIkFSgREQkSCpQIiIS\nJBUoEUlccXExr7/+eqfnaa/Zs2dTVFREnz59Ms73ne98h+OPP56RI0fy+OOPd2kG6TgVKBE5bH32\ns59l1apVGefZsGEDlZWVvPjiizz22GNcfvnlHDhwIEcJJRMVKBHpUueccw6lpaWMGTOGBQsWHNJX\nU1PDqFGjuPjiiznhhBM477zzePvtt5v6b7vtNsaPH8/YsWPZtGkTAKtWreLUU09l3LhxnHbaaWze\nvDl2llNOOYXBgwdnnGfp0qVMnTqVnj17MmzYMI4//visRU1yQwVKRLrUPffcw5o1a1i9ejW33nor\nb7zxxiH9mzdv5vLLL2fjxo3069ePO++8s6lv4MCBPPfcc8ycOZN58+YBMGrUKFasWMHatWu58cYb\n+frXv960npKSkkNeX/ziFykpKeHNN9+Mnbe2tpaioqKm6aFDh1JbW9uZTSBdJOvzoMzsn4Ad7r7f\nzMqBk4Cfunv8/wEiWaQ/k0rPo+rebr31VpYsWQLAq6++ypYtWw7pLyoq4vTTTwfgkksu4dZbb+Ur\nX/kKAOeeey4ApaWlPPTQQwDU1dUxbdo0tmzZgpnx7rvvAjBy5Eiqq6sPWXdVVRXl5eWJ/dskt+I8\nsPBBoMzMjgcWAEuB+4FPJxlMRLqfqqoqnnzySZ599lmOPvpoysvLeeeddw6Zx8zanO7ZsycAPXr0\noKGhAYBvfOMbTJo0iSVLllBTU9NUgDZv3swFF1xwyLrq6+vp06cPVVVVDBgwIFbmIUOG8OqrrzZN\n79ixgyFDhsT7B0ui4hSog+7eYGafA25z99vMbG3SwUSk+6mrq+OYY47h6KOPZtOmTaxcubLFPH/8\n4x959tlnOfXUU7n//vuZOHFi1nU2FoyFCxc2tXfVHtSUKVO46KKLuPbaa3nttdfYsmULEyZMaNc6\nJBlxzkG9a2YXAtOAR6K2o5KLJCJdoqL/e68cmTx5Mg0NDZxwwglcd911nHLKKS3mGTlyJHfccQcn\nnHACe/bsYebMmRnXOWvWLK6//nrGjRvXtFcV16xZsxg6dChvv/02Q4cOpaKiAoBly5bxzW9+E4Ax\nY8Zw/vnnM3r0aCZPnswdd9xBjx492vU5kow4e1CXAv8buMndt5vZMOBnycYSke6oZ8+ePProoy3a\na2pqgNQhuCOPPJJ77723zXkAysrKqKqqAuDUU0/lpZdeaur79re/HTvP3LlzmTt3bov2KVOmMGXK\nlKbp2bNnM3v27NjrldyIU6A+7u5XN05EReqdTAuIiIh0VpxDfNNaaZuebSEzu8fMdpvZC2ltFWZW\na2bV0evTaX3Xm9lWM9tsZp+MlV5EupXi4mJeeOGF7DOKkGEPKjrvdBEwzMyWpXX1Bf4SY90LgduB\nnzZr/093n9fss0YDU4ExwHHAk2Y2wt11O7eISIHKdIjvGWAnMBCYn9a+F1iXbcXu/lszK46Z42yg\n0t33A9vNbCswAXg25vIiInKYMXdPbuWpAvWIu58YTVeQuuiiDlgNfNnd95jZ7cBKd783mu9u4FF3\n/0Ur65wBzAAYNGhQaWVlZYfzNd4zEbL6+nq21723Izl2SMsrstbX1nVZf0fWkYuMndVdvtddmnFn\n2iXYg0s6vbqC3IYJUEaYNGnSGncvyzZfnJEkzgW+C7wfsOjl7t6vA7l+AHwL8OjrfOBf27MCd19A\n6oZhysrKvDN3jXeHu86rqqqY/7t9TdM1F5e3mGd6+igMnezvyDpykbGzusv3ukszVpz93vsL69qe\nL6aC3IYJUMb44lzFNxf4rLtv7OyHufuuxvdm9mPeu6+qFihKm3Vo1CZSuNLvX6rofIER6W7iXMW3\nqyuKE4CZpQ8r/Dmg8XKeZcBUM+sZ3Wc1HNBwwiIiBSzOHtRqM/sv4JfA/sZGd38o00Jm9gBQDgw0\nsx3ADUC5mZWQOsRXA/xbtK4XzWwxsAFoAK7QFXwiIoUtToHqB7wNfCKtzYGMBcrdL2yl+e4M898E\n3BQjj4iIFICsBcrdL81FEBHJMZ3jksBlPQdlZiPMbHnjiBBmdpKZ/Ufy0UREpJDFuUjix8D1wLsA\n7r6O1KgPIiIiiYlToI529+ZX1LVvzHsREZF2ilOgXo8e++4AZnYeqSGQREREEhPnKr4rSI3cMMrM\naoHtwCWJphIRkYIX5yq+l4GPmVlv4Ah335t8LBERKXRxxuIbAPwLUAwcaWYApD/EUEREpKvFOcT3\na2AlsB44mGwcEYlN9zHJYS5Ogerl7tcmnkRERCRNnAL1MzP7X6RGHk8fiy/OU3VFpC3aAxLJKE6B\n+htwMzCb6FLz6OsHkgolIgGoaPbgyPKl+ckhBStOgfoycLy7v550GBERkUZxbtTdSmo0cxERkZyJ\nswe1D6g2s6c49ByULjMXEZHExClQv4xeIiIiORNnJIlFuQgiIiKSLs5IEtt57+q9Ju6uq/hERCQx\ncQ7xlaW97wV8Hjg2mTgiIiIpWa/ic/c30l617v494KwcZBMRkQIW5xDf+LTJI0jtUcXZ8xIREemw\nOIVmftr7BlLPgzo/mTgiIiIpca7im5SLICIiIumynoMys/8bPROqcfoYM/t2srEKS/F1v2p6iYhI\nSpyhjj7l7m82Trj7HuDTyUUSERGJdw6qh5n1dPf9AGb290DPZGOJyGFBjxSRTohToO4DlpvZT6Lp\nSwGNLiE51fzwZ80c3ekgcriLc5HEd83seeBjUdO33P3xZGOJiEihi3s/01rgKFJDHq1NLo6IiEhK\nnBt1zyf1RN0qwIDbzOyr7v6LhLOJyOFO56gkgzh7ULOBD7r7bgAzex/wJKACJdKW5o9LP1x/+arA\nSILiXGZ+RGNxirwRczkREZEOi7MH9ZiZPQ48EE1fAPw6uUgiIiLxruL7qpn9M3B61LTA3ZckG0tE\nRApdrKv43P1B4MGEs4iIiDRps0CZ2V5aeZJuI3fvl0giERERMhQod+8LYGbfAnYCPyN1mfnFwOCc\npBMRkYIV52q8Ke5+p7vvdfe33P0HwNlJBxMRkcIW5xzUPjO7GKgkdcjvQmBfoqlE2klj9YkcfuLs\nQV1E6gm6u6LX56M2ERGRxGQtUO5e4+5nu/tAd3+fu5/j7jXZljOze8xst5m9kNZ2rJk9YWZboq/H\npPVdb2ZbzWyzmX2yw/8iERE5LCQ5IsRCYHKztuuA5e4+HFgeTWNmo4GpwJhomTvNrEeC2UREJHCJ\nFSh3/y3wl2bNZ/Pes6QWAeektVe6+3533w5sBSYklU1ERMJn7q3f6mRm17j7983sdHf/fx1auVkx\n8Ii7nxhNv+nuA6L3Buxx9wFmdjuw0t3vjfruBh5tbcR0M5sBzAAYNGhQaWVlZUeiAVBfX0+fPn06\nvHxXWV/73iCbY4ccOshofX092+sOtNmfbfn29ndkHSFkzNaf8+/1zupDpweXZJ5ncEnLjM36sy2f\naD9Q3/f4ltsw6QztFMrPdCbKCJMmTVrj7mXZ5st0Fd+lwPeB24DxXRWskbu7mbV5I3CG5RYACwDK\nysq8vLy8wxmqqqrozPJdZXraFWg1F5cf0ldVVcX83+1rsz/b8u3t78g6QsiYrT/n3+uKZndiXNjK\nSN/p81xY1zJjs/5syyfaD1SVL225DZPO0E6h/ExnoozxZSpQG81sC3Ccma1LazdS9eWkDnzeLjMb\n7O47zWww0DhKei1QlDbf0KhNREQKVKaRJC40s38AHgemdNHnLQOmAXOir0vT2u83s1uA44DhwKou\n+kwREemGMt6o6+5/Ak42s78DRkTNm9393WwrNrMHgHJgoJntAG4gVZgWm9llwCuk7q/C3V80s8XA\nBqABuMLdD7S6YhERKQhxHvn+EeCnQA2pw3tFZjYtukqvTe5+YRtdZ7Yx/03ATdnyiIhIYYgz1NEt\nwCfcfTOAmY0g9fDC0iSDiQRNjzoXSVyc+6COaixOAO7+EnBUcpFERETi7UGtNrO7gHuj6YuB1clF\nEhERiVegZgJXAFdH0yuAOxNLJCLSSIdSC1rWAuXu+0mdh7ol+TgiIiIpSQ4WKyIi0mEqUCIiEqSM\nBcrMepjZvFyFERERaZSxQEWjOUzMURYREZEmca7iW2tmy4CfA01DVrv7Q4mlOswUp4/UPeesPCYR\nEek+4hSoXsAbwEfT2hxQgRIRkcTEucz80lwEEQmK7r8Rybs2C5SZfTPDcu7u30ogj4iICJB5D2pf\nK229gcuA/wGoQImISGIyPbBwfuN7M+sLXEPqMfCVwPy2lhMREekKGc9BmdmxwLWkBohdBIx39z25\nCCYiIoUt0zmom4FzgQXAWHevz1kqEREpeJlu1P0ycBzwH8BrZvZW9NprZm/lJp6IiBSqTOegNE6f\niIjkjYqQiIgEKc5IEiKHH92IKxI8FSgR6b7S/9AAKF+anxySCB3iExGRIKlAiYhIkFSgREQkSCpQ\nIiISJF0kIQXjkAdH9spjEBGJRXtQIiISJBUoEREJkgqUiIgESQVKRESCpAIlIiJBUoESEZEgqUCJ\niEiQdB+USET3SYmERXtQIiISJBUoEREJkgqUiIgESQVKRESCpAIlIiJBystVfGZWA+wFDgAN7l5m\nZscC/wUUAzXA+e6+Jx/5REQk//K5BzXJ3UvcvSyavg5Y7u7DgeXRtIiIFKiQDvGdDSyK3i8Czslj\nFhERyTNz99x/qNl2oI7UIb4fufsCM3vT3QdE/QbsaZxutuwMYAbAoEGDSisrKzuco76+nj59+nR4\n+bjW19Y1vR87pH+7+uvr69led6DDy7e3v7tmzNbfIuMR29/rHFzSMkMr/YfYWR2/P+Y6Wvx/bM9n\nJN0P1Pc9vuXPS3fIGJhc/d7pjKQzTpo0aU3a0bM25atADXH3WjN7P/AEcBWwLL0gmdkedz8m03rK\nysp89erVHc5RVVVFeXl5h5eP65ARCuac1a7+qqoqpj+2r8PLt7e/u2bM1t8iY6+L3uusqGuZoZX+\nQ1T0j98fcx0t/j+25zOS7geqype2/HkJPWOc70OO5er3TmckndHMYhWovBzic/fa6OtuYAkwAdhl\nZoMBoq+785FNRETCkPMCZWa9zaxv43vgE8ALwDJgWjTbNGBprrOJiEg48nGZ+SBgSeo0E0cC97v7\nY2b2B2CxmV0GvAKcn4dsIiISiJwXKHd/GTi5lfY3gDNznUdERMKkx210UpwLDCQPsp1cF5HghXQf\nlIiISBMVKBERCZIKlIiIBEnnoESksOl8ZbC0ByUiIkFSgRIRkSCpQImISJB0DkrC04GBVkXk8KM9\nKBERCZIKlIiIBEkFSkREgqRzUCIimeh8Z95oD0pERIKkAiUiIkFSgRIRkSDpHJTkno7pi0gMKlAi\nIp2hP7gSowIlElP605NreuUxiEiBUIGS9tNfjCKSAypQ0vVUwESkC+gqPhERCZL2oApNnJHCRaTr\n6IhCh2kPSkREgqQ9qMON9pBE5DChAhUaHQ4QEQFUoLI65N6XOWflMYmISGFRgco17SEdtrLdyJve\n39Y8IvIeFSgRkZAV8HllFajuJhd7YNrLE5EA6DJzEREJkgqUiIgESQVKRESCpAIlIiJBUoESEZEg\n6So+EZF8KuDLyLPRHpSIiARJe1BdTfcQiYh0CRWo9tCuuCRofW0d07MMlyTSqs7+YRzoH9YqUCLd\nSLbx/kQSkacCFtw5KDObbGabzWyrmV2X7zwiIpIfQe1BmVkP4A7g48AO4A9mtszdN+Q3mUj3oD0s\naVWgh/CyCW0PagKw1d1fdve/AZXA2XnOJCIieWDunu8MTczsPGCyu38xmv4C8CF3vzJtnhnAjGhy\nJLC5Ex85EHi9E8vngjJ2DWXsvNDzgTJ2laQz/qO7vy/bTEEd4ovD3RcAC7piXWa22t3LumJdSVHG\nrqGMnRd6PlDGrhJKxtAO8dUCRWnTQ6M2EREpMKEVqD8Aw81smJn9HTAVWJbnTCIikgdBHeJz9wYz\nuxJ4HOgB3OPuLyb4kV1yqDBhytg1lLHzQs8HythVgsgY1EUSIiIijUI7xCciIgKoQImISKAKtkB1\nhyGVzKzGzNabWbWZrc53HgAzu8fMdpvZC2ltx5rZE2a2Jfp6TIAZK8ysNtqW1Wb26TzmKzKzp8xs\ng5m9aGbXRO3BbMcMGUPajr3MbJWZPR9l/D9Re0jbsa2MwWzHKE8PM1trZo9E00Fsw4I8BxUNqfQS\naUMqAReGNqSSmdUAZe4ezE19ZvZhoB74qbufGLXNBf7i7nOiYn+Mu38tsIwVQL27z8tXrkZmNhgY\n7O7PmVlfYA1wDjCdQLZjhoznE852NKC3u9eb2VHA74BrgHMJZzu2lXEygWxHADO7FigD+rn7Z0L5\nmS7UPSgNqdRB7v5b4C/Nms8GFkXvF5H6RZY3bWQMhrvvdPfnovd7gY3AEALajhkyBsNT6qPJo6KX\nE9Z2bCtjMMxsKHAWcFdacxDbsFAL1BDg1bTpHQT2wxdx4EkzWxMN8RSqQe6+M3r/J2BQPsNkcJWZ\nrYsOAeb1MGQjMysGxgG/J9Dt2CwjBLQdo0NT1cBu4Al3D247tpERwtmO3wNmAQfT2oLYhoVaoLqL\nie5eAnwKuCI6dBU0Tx0zDuovxMgPgA8AJcBOYH5+44CZ9QEeBL7k7m+l94WyHVvJGNR2dPcD0c/I\nUGCCmZ3YrD/v27GNjEFsRzP7DLDb3de0NU8+t2GhFqhuMaSSu9dGX3cDS0gdmgzRruicReO5i915\nztOCu++KflEcBH5MnrdldD7iQeA+d38oag5qO7aWMbTt2Mjd3wSeInVuJ6jt2Cg9Y0Db8XRgSnS+\nuxL4qJndSyDbsFALVPBDKplZ7+jkNGbWG/gE8ELmpfJmGTAtej8NWJrHLK1q/GGLfI48bsvoxPnd\nwEZ3vyWtK5jt2FbGwLbj+8xsQPT+70ld9LSJsLZjqxlD2Y7ufr27D3X3YlK/B3/j7pcQyDYMaqij\nXMnDkEodMQhYkvo9wZHA/e7+WH4jgZk9AJQDA81sB3ADMAdYbGaXAa+QutIrb9rIWG5mJaQOVdQA\n/5a3gKm/Wr8ArI/OTQB8nbC2Y1sZLwxoOw4GFkVX5R4BLHb3R8zsWcLZjm1l/FlA27E1QfxfLMjL\nzEVEJHyFeohPREQCpwIlIiJBUoESEZEgqUCJiEiQVKBERCRIKlAiMZmZm9n8tOmvRIPQdmadD0TD\n3fx7s/ZzzGx0J9Y7xQIdpV8kLhUokfj2A+ea2cBMM5lZrPsLzewfgA+6+0nu/p/Nus8BOlyg3H2Z\nu8/p6PIiIVCBEomvAVgA/HvzDjNbaGY/NLPfA3Ob9fUys59Y6tlea81sUtT138AQSz0P6Iy0+U8D\npgA3R33/ZGYlZrYy2tta0ji4qJlVmdn3o/leMLMJUft0M7s9ej8oWub56HVaNFLJr6LpF8zsggS2\nl0inFORIEiKdcAewLnpeTnNDgdPc/UCz9itIjbk51sxGAf9tZiNIFaFHooFEm7j7M2a2LOr7BYCZ\nrQOucvenzexGUqNjfCla5Gh3L4kGE74HOGTAVOBW4Gl3/1w0okEfUmPWvebuZ0Xr79+RjSGSJO1B\nibRDNKL3T4GrW+n+eSvFCWAicG+0/CZSQ8eMiPuZUfEY4O5PR02LgPSR7R+I1v1boF/j2G9pPkpq\n9OzGkbXrgPXAx83su2Z2RtQmEhQVKJH2+x5wGdC7Wfu+PGSBlo9CyDp+mbu/BIwnVai+bWbfTCKY\nSGeoQIm0k7v/BVhMqkjFsQK4GCA6tPc/gc1ZltkL9I0+rw7Yk3ae6gvA02nzXhCteyJQ18re0HJg\nZjRPDzPrb2bHAW+7+73AzaSKlUhQdA5KpGPmA1fGnPdO4Admtp7UhRbT3X1/NFJ9WyqBH5vZ1cB5\npB558EMzOxp4Gbg0bd53zGwtqceJ/2sr67oGWBCNTH2AVLHqR+oijIPAu1GbSFA0mrlIN2ZmVcBX\n3H11vrOIdDUd4hMRkSBpD0pERIKkPSgREQmSCpSIiARJBUpERIKkAiUiIkFSgRIRkSD9fwijkZOP\n/yNRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc0c92e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.hist([num_topics_used, num_topics_used1], np.arange(42))\n",
    "ax.set_ylabel('Nr of documents')\n",
    "ax.set_xlabel('Nr of topics')\n",
    "\n",
    "# Координаты ниже были получены методом проб и ошибок,\n",
    "# чтобы хорошо смотреться\n",
    "ax.text(9, 223, r'default alpha')\n",
    "ax.text(26, 156, 'alpha=1.0')\n",
    "ax.grid()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это значение alpha больше подразумеваемого по умолчанию, поэтому у каждого документа должно быть больше тем. На комбинированной гистограмме видно, что gensim ведет себя в соответствии с ожиданиями - с каждым документом теперь ассоциировано больше тем. Сейчас для многих документов __количество тем варьируется от 20 до 25__. Если уменьшить значение, то будет наблюдаться противоположная тенденция.\n",
    "\n",
    "Что это за темы? Технически это __мультиномиальное распределение (multinomial distributions) по словам__, то есть каждому слову из словаря назначается вероятность относительно некоторой темы. Чем выше вероятность, тем больше шансов, что слово связано с данной темой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наш мозг плохо приспособлен для рассуждений о распределениях вероятности, но список слов мы воспринимаем легко. Поэтому обычно темы описываются списком слов с наибольшими вероятностями. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ti in range(model.num_topics):\n",
    "    words = model.show_topic(ti, 64)\n",
    "    tf = sum(f for w, f in words)\n",
    "\n",
    "    with open('./data/topics.txt', 'w') as output:\n",
    "        output.write('\\n'.join('{0} : {1}'.format(w, int(1000. * f / tf)) for w, f in words))\n",
    "        output.write(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В таблице перечислены первые десять тем из файла __topics.txt__:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./img/first-ten-topics.jpg\" width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На первый взгляд, полная неразбериха, но, вчитавшись в список слов, мы начинаем понимать, что темы - не просто произвольно выхваченные слова, а __образуют логические группы__. Мы также видим, что темы относятся к старым новостям - к тому времени, когда еще существовал Советский Союз, а Горбачев был Генеральным секретарем.\n",
    "\n",
    "Темы можно представить также __в виде облака слов__, в котором слова с большей вероятностью набраны более крупным шрифтом.\n",
    "Вот, например, как выглядит тема, относящаяся к политике на Ближнем Востоке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import matutils\n",
    "topics = matutils.corpus2dense(model[corpus], num_terms=model.num_topics)\n",
    "\n",
    "# Сначала определяем наиболее обсуждаемые темы, \n",
    "# т.е. с наибольшим общим весом\n",
    "weight = topics.sum(1)\n",
    "max_topic = weight.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytagcloud in e:\\python\\anaconda2\\lib\\site-packages\n",
      "Requirement already satisfied: pygame in e:\\python\\anaconda2\\lib\\site-packages\n",
      "Requirement already satisfied: simplejson in e:\\python\\anaconda2\\lib\\site-packages\n"
     ]
    }
   ],
   "source": [
    "!pip install pytagcloud\n",
    "!pip install pygame\n",
    "!pip install simplejson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pytagcloud import create_tag_image, make_tags\n",
    "\n",
    "def create_cloud(oname, words,maxsize=120, fontname='Lobster'):\n",
    "    '''Создание облака слов (word cloud) (если pytagcloud установлен)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    oname : имя выходного файла\n",
    "    words : список (value,str)\n",
    "    maxsize : int, optional\n",
    "        Размер maximum word. Оптимальная настройка этого параметра часто\n",
    "        требует некоторой ручной настройки для каждого input.\n",
    "    fontname : str, optional\n",
    "        используемый шрифт\n",
    "    '''\n",
    "\n",
    "    # gensim возвращает вес между 0 и 1 для каждого слова, в то время как pytagcloud\n",
    "    # ожидает integer word count. Поэтому, мы перемножаем large number и округляем\n",
    "    # Для визуализации это достаточное приближение.\n",
    "    # Нам также необходимо перевернуть порядок т.к. gensim возвращает (value, word), whilst\n",
    "    # тогда как pytagcloud требует (word, value):\n",
    "    words = [(w,int(v*10000)) for w,v in words]\n",
    "    tags = make_tags(words, maxsize=maxsize)\n",
    "    create_tag_image(tags, oname, size=(1800, 1200), fontname=fontname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Получаем верхние 64 слова по этой теме\n",
    "# Без аргумента show_topic будет возвращать 10 слов\n",
    "words = model.show_topic(max_topic, 64)\n",
    "create_cloud(\"./img/cloud_blei_lda.png\", words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./img/cloud_blei_lda.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно также, что некоторые слова имело бы смысл удалить (например, слово \"i\" ), потому что они малоинформативны - являются стоп-словами. __При построении тематической модели полезно__ отфильтровывать стоп-слова, иначе могут появиться темы, целиком составленные из таких слов. Кроме того, желательно произвести предварительную обработку - стемминг для нормализации форм множественного числа и глагольных форм."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сравнение документов по темам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Темы могут быть полезны сами по себе для построения своего рода виньеток (vignettes) из слов, как на рисунке выше. Такие наглядные представления можно использовать для навигации по большим наборам документов. Например, на сайте разные темы можно показать в виде разных облаков слов, позволяющих пользователю с помощью нескольких щелчков мышью добраться до документов. На самом деле, именно такая методика реально применялась для анализа больших наборов документов.\n",
    "\n",
    "Однако чаще __темы служат промежуточным средством__ для достижения другой цели. Теперь, когда у нас для каждого документа имеется оценка соотнесенности его с разными темам и мы можем сравнивать документы в пространстве тем. Это означает, что __мы сравниваем документы не по отдельным словам, а по тому, насколько близки затрагиваемые в них темы__.\n",
    "\n",
    "И это очень эффективный подход, потому что два текстовых документа, почти не имеющие общих слов могут, тем не менее, относиться к одной и той же теме! Возможно, в них просто используются разные словесные конструкции (скажем, в одном документе говорится о \"президенте США\", а в другом - о \"Бараке Обаме\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно искать сообщение, больше всего похожее на заданное в вопросе, исходя из сходства по темам. Если раньше при сравнении двух документов мы использовали их векторы слов, то теперь __сравним векторы тем.__\n",
    "\n",
    "Для этого спроецируем документы в пространство тем. Иначе говоря, мы хотим __построить вектор тем, описывающий документ (задача понижения размерности)__. Вычислив для каждого документа вектор тем, мы сможем производить, над этими векторами различные операции, забыв об исходных словах. __Если темы значимы, то они потенциально могут оказаться более информатнвными, чем сами слова__. Кроме того, так можно и __сэкономить на вычислениях__, потому что сравнить векторы\n",
    "с вероятностями сотни тем гораздо быстрее, чем векторы, размер которых сравним с размером словаря (тысячи термов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk.corpus\n",
    "import nltk.stem\n",
    "\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "from gensim import corpora, models\n",
    "import sklearn.datasets\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "english_stemmer = nltk.stem.SnowballStemmer('english')\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "stopwords.update(['from:', 'subject:', 'writes:', 'writes'])\n",
    "\n",
    "class DirectText(corpora.textcorpus.TextCorpus):\n",
    "\n",
    "    def get_texts(self):\n",
    "        return self.input\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    dataset = sklearn.datasets.load_mlcomp(\"20news-18828\", \"train\", mlcomp_root='./data')\n",
    "except:\n",
    "    print(\"Newsgroup data not found.\")\n",
    "    print(\"Please download from http://mlcomp.org/datasets/379\")\n",
    "    print(\"And expand the zip into the subdirectory data/\")\n",
    "    print(\"\\n\" * 2)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "otexts = dataset.data\n",
    "texts = dataset.data\n",
    "\n",
    "texts = [t.decode('utf-8', 'ignore') for t in texts]\n",
    "texts = [t.split() for t in texts]\n",
    "texts = [map(lambda w: w.lower(), t) for t in texts]\n",
    "texts = [filter(lambda s: not len(set(\"+-.?!()>@012345689\") & set(s)), t) for t in texts]\n",
    "texts = [filter(lambda s: (len(s) > 3) and (s not in stopwords), t) for t in texts]\n",
    "texts = [map(english_stemmer.stem, t) for t in texts]\n",
    "\n",
    "usage = defaultdict(int)\n",
    "for t in texts:\n",
    "    for w in set(t):\n",
    "        usage[w] += 1\n",
    "\n",
    "limit = len(texts) / 10\n",
    "too_common = [w for w in usage if usage[w] > limit]\n",
    "too_common = set(too_common)\n",
    "texts = [filter(lambda s: s not in too_common, t) for t in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = DirectText(texts)\n",
    "dictionary = corpus.dictionary\n",
    "try:\n",
    "    dictionary['computer']\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model = models.ldamodel.LdaModel(corpus, num_topics=100, id2word=dictionary.id2token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видели, как с помощью пакета gensim вычислить темы всех документов из корпуса. Сделаем это, сохраним результаты в массивах NumPy и вычислим попарные расстояния:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim import matutils\n",
    "topics = matutils.corpus2dense(model[corpus], num_terms=model.num_topics)\n",
    "\n",
    "thetas = np.zeros((len(texts), 100))\n",
    "for i, c in enumerate(corpus):\n",
    "    for ti, v in model[c]:\n",
    "        thetas[i, ti] += v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переменная __topics__: содержит матрицу тем. Для вычисления попарных расстояний можно воспользоваться функцией __pdist__ из библиотеки SciPy. Один ее вызов вычисляет все значения sum((topics[ti] - topics[tj])\\**2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "pairwise = distance.squareform(distance.pdist(topics))\n",
    "distances = distance.squareform(distance.pdist(thetas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее применим еще один трюк; присвоим диагональным элементам матрицы __distance__ некое большое значение (оно должно быть больше всех остальных элементов матрицы):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "largest = pairwise.max()\n",
    "for ti in range (len (topics)):\n",
    "    pairwise[ti,ti] = largest + 1\n",
    "    \n",
    "large = distances.max() + 1\n",
    "for i in range(len(distances)):\n",
    "    distances[i, i] = large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отметим, что это решение не сработало бы, если бы мы не присвоили диагональным элементам большое значение: функция всегда возвращала бы сам документ, потому что он больше всего похож на себя самого (за исключением маловероятного случая, когда у двух элементов в точности одинаковое распределение вероятностей тем, что практически невозможно, если только они не совпадают буквально)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот и всё! Для каждого документа можно легко найти ближайший к нему (получился вариант классификатора по ближайшему\n",
    "соседу):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: geb@cs.pitt.edu (Gordon Banks)\n",
      "Subject: Re: request for information on \"essential tremor\" and Indrol?\n",
      "\n",
      "In article <1q1tbnINNnfn@life.ai.mit.edu> sundar@ai.mit.edu writes:\n",
      "\n",
      "Essential tremor is a progressive hereditary tremor that gets worse\n",
      "when the patient tries to use the effected member.  All limbs, vocal\n",
      "cords, and head can be involved.  Inderal is a beta-blocker and\n",
      "is usually effective in diminishing the tremor.  Alcohol and mysoline\n",
      "are also effective, but alcohol is too toxic to use as a treatment.\n",
      "-- \n",
      "----------------------------------------------------------------------------\n",
      "Gordon Banks  N3JXP      | \"Skepticism is the chastity of the intellect, and\n",
      "geb@cadre.dsl.pitt.edu   |  it is shameful to surrender it too soon.\" \n",
      "----------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(otexts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы попросим найти наиболее похожий документ - __closest_to(1)__ - то получим такой результат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def closest_to(doc_id):\n",
    "    return pairwise[doc_id].argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: eshneken@ux4.cso.uiuc.edu (Edward A Shnekendorf)\n",
      "Subject: Re: was: Go Hezbollah!!\n",
      "\n",
      "amehdi@src.honeywell.com (Hossien Amehdi) writes:\n",
      "\n",
      ">In article <C5HuBA.CJo@news.cso.uiuc.edu> eshneken@ux4.cso.uiuc.edu (Edward A Shnekendorf) writes:\n",
      ">>amehdi@src.honeywell.com (Hossien Amehdi) writes:\n",
      ">>\n",
      ">>>You know when Israelis F16 (thanks to General Dynamics) fly high in the sky\n",
      ">>>and bomb the hell out of some village in Lebanon, where civilians including\n",
      ">>>babies and eldery getting killed, is that plain murder or what?\n",
      ">>\n",
      ">>If you Arabs wouldn't position guerilla bases in refugee camps, artillery \n",
      ">>batteries atop apartment buildings, and munitions dumps in hospitals, maybe\n",
      ">>civilians wouldn't get killed.  Kinda like Saddam Hussein putting civilians\n",
      ">>in a military bunker.  \n",
      ">>\n",
      ">>Ed.\n",
      "\n",
      ">Who is the you Arabs here.  Since you are replying to my article you\n",
      ">are assuming that I am an Arab.  Well, I'm not an Arab, but I think you\n",
      ">are brain is full of shit if you really believe what you said.  The\n",
      ">bombardment of civilian and none civilian areas in Lebanon by Israel is\n",
      ">very consistent with its policy of intimidation.  That is the only\n",
      ">policy that has been practiced by the so called only democracy in\n",
      ">the middle east!\n",
      "\n",
      "What the hell do you know about Israeli policy?  What gives you the fiat\n",
      "to look into the minds of Israeli generals?  Has this 'policy of intimidation'\n",
      "been published somewhere?  For your information, the actions taken by Arabs,\n",
      "specifically the PLO, were not uncommon in the Lebanon Campaign of 1982.  My\n",
      "brain is full of shit?  At least I don't look into the minds of others and \n",
      "make Israeli policy for them!\n",
      "\n",
      ">I was merley pointing out that the other side is also suffering.\n",
      ">Like I said, I'm not an Arab but if I was, say a Lebanese, you bet\n",
      ">I would defende my homeland against any invader by any means.\n",
      "\n",
      "Yeah, yeah, yeah.  We all suffer.  It's too bad that civilians get killed but\n",
      "I will blame their Arab leaders who put them in positions of danger before I\n",
      "will blame the Israelis.  Just like Palestinians who send their children into\n",
      "warzones to throw rocks at armed Israeli soldiers.  What irresponsible parents!\n",
      "As Golda Meir said, peace will only come when the Arabs start loving their\n",
      "children more than they hate the Jews.\n",
      "\n",
      "Ed.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(otexts[closest_to(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: geb@cs.pitt.edu (Gordon Banks)\n",
      "Subject: Re: Sinus vs. Migraine (was Re: Sinus Endoscopy)\n",
      "\n",
      "In article <Lauger-240393141539@lauger.mdc.com> Lauger@ssdgwy.mdc.com (John Lauger) writes:\n",
      ">In article <19201@pitt.UUCP>, geb@cs.pitt.edu (Gordon Banks) wrote:\n",
      "\n",
      ">What's the best approach to getting off the analgesics.  Is there something\n",
      "\n",
      "Two approaches that I've used: Tofranil, 50 mg qhs, Naproxen 250mg bid.\n",
      "The Naproxen doesn't seem to be as bad as things like Tylenol in promoting\n",
      "the analgesic abuse Headache.  DHE IV infusions for about 3 days (in\n",
      "hospital).  Cold turkey is the only way I think.  Tapering doesn't\n",
      "help. I wouldn't know how you can do this without your doctor.  I haven't\n",
      "seen anyone successfully do it alone.  Doesn't mean it can't be done.\n",
      "-- \n",
      "----------------------------------------------------------------------------\n",
      "Gordon Banks  N3JXP      | \"Skepticism is the chastity of the intellect, and\n",
      "geb@cadre.dsl.pitt.edu   |  it is shameful to surrender it too soon.\" \n",
      "----------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(otexts[distances[1].argmin()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
